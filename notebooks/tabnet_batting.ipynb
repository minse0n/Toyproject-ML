{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f19d065",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "672497f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import MinMaxScaler    \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "dataframe = pd.read_csv('data/raw/kbo_batting_stats_by_season_1982-2025.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0257b6eb",
   "metadata": {},
   "source": [
    "#### Batting Model (Regression) \n",
    "\n",
    "input = batting stas\n",
    "\n",
    "target = [WAR, WRC+]\n",
    "\n",
    "- **WAR** : **Wins Above Replacement**, a premier, all-encompassing sabermetric statistic measuring a player’s total value by quantifying how many more wins they provide to their team compared to a readily available \"replacement-level\" player\n",
    "- **WRC+** : **Weighted Runs Created Plus**, a stat that measures a hitter's overall offensive value compared to league average. It takes all of a hitter's contributions at the plate and translates that to his impact on runs created for his team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec307f8",
   "metadata": {},
   "source": [
    "Source\n",
    "- https://medium.com/@turkishtechnology/deep-learning-with-tabnet-b881236e28c1\n",
    "- \"TabNet: Attentive Interpretable Tabular Learning\", Sercan O. Arık, Tomas Pfister, Google Cloud AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eff9cb2",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bb2afa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 10350.25601| val_0_rmse: 1049.23486|  0:00:00s\n",
      "epoch 1  | loss: 6680.90642| val_0_rmse: 338.10996|  0:00:01s\n",
      "epoch 2  | loss: 3207.2881| val_0_rmse: 1026.43198|  0:00:01s\n",
      "epoch 3  | loss: 1659.91085| val_0_rmse: 529.43342|  0:00:02s\n",
      "epoch 4  | loss: 798.60811| val_0_rmse: 465.30141|  0:00:02s\n",
      "epoch 5  | loss: 600.19621| val_0_rmse: 418.96251|  0:00:03s\n",
      "epoch 6  | loss: 638.65442| val_0_rmse: 443.74549|  0:00:03s\n",
      "epoch 7  | loss: 542.65289| val_0_rmse: 376.04273|  0:00:03s\n",
      "epoch 8  | loss: 529.46982| val_0_rmse: 63.25964|  0:00:04s\n",
      "epoch 9  | loss: 534.33131| val_0_rmse: 60.40094|  0:00:04s\n",
      "epoch 10 | loss: 531.06708| val_0_rmse: 59.6507 |  0:00:05s\n",
      "epoch 11 | loss: 522.09255| val_0_rmse: 204.19294|  0:00:05s\n",
      "epoch 12 | loss: 485.60542| val_0_rmse: 339.71713|  0:00:06s\n",
      "epoch 13 | loss: 548.07045| val_0_rmse: 477.67848|  0:00:06s\n",
      "epoch 14 | loss: 576.88401| val_0_rmse: 483.73048|  0:00:07s\n",
      "epoch 15 | loss: 490.79469| val_0_rmse: 511.27829|  0:00:07s\n",
      "epoch 16 | loss: 444.30952| val_0_rmse: 467.68031|  0:00:08s\n",
      "epoch 17 | loss: 394.90212| val_0_rmse: 332.02274|  0:00:08s\n",
      "epoch 18 | loss: 472.85305| val_0_rmse: 96.69169|  0:00:09s\n",
      "epoch 19 | loss: 377.12213| val_0_rmse: 72.70193|  0:00:09s\n",
      "epoch 20 | loss: 305.5146| val_0_rmse: 73.35747|  0:00:10s\n",
      "epoch 21 | loss: 297.80745| val_0_rmse: 75.92723|  0:00:10s\n",
      "epoch 22 | loss: 259.5612| val_0_rmse: 71.24827|  0:00:11s\n",
      "epoch 23 | loss: 298.74214| val_0_rmse: 70.11192|  0:00:11s\n",
      "epoch 24 | loss: 280.0191| val_0_rmse: 80.09478|  0:00:12s\n",
      "epoch 25 | loss: 260.83986| val_0_rmse: 90.52419|  0:00:12s\n",
      "epoch 26 | loss: 290.79032| val_0_rmse: 101.74543|  0:00:13s\n",
      "epoch 27 | loss: 285.27421| val_0_rmse: 77.38378|  0:00:13s\n",
      "epoch 28 | loss: 225.95252| val_0_rmse: 75.60976|  0:00:14s\n",
      "epoch 29 | loss: 235.82271| val_0_rmse: 87.50151|  0:00:14s\n",
      "epoch 30 | loss: 200.57654| val_0_rmse: 111.36428|  0:00:15s\n",
      "epoch 31 | loss: 229.14515| val_0_rmse: 148.24313|  0:00:15s\n",
      "epoch 32 | loss: 238.36304| val_0_rmse: 127.24606|  0:00:16s\n",
      "epoch 33 | loss: 225.29019| val_0_rmse: 104.25785|  0:00:16s\n",
      "epoch 34 | loss: 219.46263| val_0_rmse: 107.00554|  0:00:17s\n",
      "epoch 35 | loss: 199.85795| val_0_rmse: 107.3911|  0:00:17s\n",
      "epoch 36 | loss: 172.28094| val_0_rmse: 106.65588|  0:00:17s\n",
      "epoch 37 | loss: 181.4722| val_0_rmse: 102.67167|  0:00:18s\n",
      "epoch 38 | loss: 161.5584| val_0_rmse: 112.78128|  0:00:18s\n",
      "epoch 39 | loss: 178.44263| val_0_rmse: 93.92617|  0:00:19s\n",
      "epoch 40 | loss: 174.76236| val_0_rmse: 113.28387|  0:00:19s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 10 and best_val_0_rmse = 59.6507\n",
      "\n",
      "--- [학습 결과 보고서] ---\n",
      "테스트 RMSE (오차): 74.6909\n",
      "결정계수 R2 (설명력): 0.4242\n",
      "\n",
      "--- [상위 5개 중요 피처] ---\n",
      "   feature  importance\n",
      "28     OPS    0.396994\n",
      "23      SH    0.191105\n",
      "26     OBP    0.113206\n",
      "4     Pos.    0.092881\n",
      "25     AVG    0.082690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "# 1. 데이터 로드 및 타겟 설정\n",
    "# [선택 이유] KBO 역사(1982-2025)를 담은 시계열적 성격이 강한 데이터셋입니다.\n",
    "try:\n",
    "    df = pd.read_csv(\"data/raw/kbo_batting_stats_by_season_1982-2025.csv\")\n",
    "except FileNotFoundError:\n",
    "    # 파일이 없을 경우를 대비한 가상 구조 (테스트용)\n",
    "    print(\"파일을 찾을 수 없습니다. 예시 데이터 구조로 진행합니다.\")\n",
    "    pass\n",
    "\n",
    "TARGET = \"wRC+\"\n",
    "df = df.dropna(subset=[TARGET]).copy()\n",
    "\n",
    "# 2. 피처 엔지니어링 및 불필요한 컬럼 제거\n",
    "# [선택 이유] 'Id'는 순수 식별자이며, 'Birthdate'는 'Age'와 정보가 겹치므로 모델의 혼란을 줄이기 위해 제거합니다.\n",
    "# 'Name'은 선수의 고유 능력을 모델이 기억하게 하기 위해 범주형 변수로 유지합니다.\n",
    "drop_cols = [\"Id\", \"Name\", \"Birthdate\", \"School\", \"Draft\", \"oWAR\", \"dWAR\", \"WAR\"]\n",
    "df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
    "\n",
    "# 3. 시계열 분할 (Time-based Splitting)\n",
    "# [선택 이유] 스포츠 데이터는 연도별 에이징 커브나 리그 전체의 타고투저 경향이 변하므로 \n",
    "# 무작위 분할보다 '연도 기반' 분할이 미래 성능 예측에 훨씬 정확합니다.\n",
    "train_df = df[df[\"Year\"] <= 2022].copy()\n",
    "valid_df = df[df[\"Year\"] == 2023].copy()\n",
    "test_df  = df[df[\"Year\"] >= 2024].copy()\n",
    "\n",
    "# 4. 범주형 변수 처리 (Label Encoding)\n",
    "# [선택 이유] TabNet은 내부적으로 Embedding 레이어를 가집니다. \n",
    "# One-hot encoding을 하면 차원이 너무 커지지만, Label Encoding 후 cat_dims를 알려주면 \n",
    "# 모델이 각 범주(팀, 포지션 등)의 의미적 거리를 스스로 학습합니다.\n",
    "cat_cols = [\"Handedness\", \"Team\", \"Pos.\"]\n",
    "cat_cols = [c for c in cat_cols if c in df.columns]\n",
    "\n",
    "encoders = {}\n",
    "for c in cat_cols:\n",
    "    le = LabelEncoder()\n",
    "    # [중요 수정] 전체 데이터의 범주를 학습하여 인덱스 범위를 확정합니다.\n",
    "    all_vals = pd.concat([train_df[c], valid_df[c], test_df[c]], axis=0).astype(str).fillna(\"NA\")\n",
    "    le.fit(all_vals)\n",
    "    encoders[c] = le\n",
    "    \n",
    "    train_df[c] = le.transform(train_df[c].astype(str).fillna(\"NA\"))\n",
    "    valid_df[c] = le.transform(valid_df[c].astype(str).fillna(\"NA\"))\n",
    "    test_df[c]  = le.transform(test_df[c].astype(str).fillna(\"NA\"))\n",
    "\n",
    "# 5. 수치형 변수 결측치 처리\n",
    "# [선택 이유] TabNet은 결측치에 강한 편이지만, 명시적으로 중앙값(Median) 처리를 하여 \n",
    "# 이상치(Outlier)의 영향을 최소화하면서 학습 안정성을 높입니다.\n",
    "feature_cols = [c for c in df.columns if c != TARGET]\n",
    "for c in feature_cols:\n",
    "    if c in cat_cols: continue\n",
    "    median_val = train_df[c].median()\n",
    "    train_df[c] = train_df[c].fillna(median_val)\n",
    "    valid_df[c] = valid_df[c].fillna(median_val)\n",
    "    test_df[c]  = test_df[c].fillna(median_val)\n",
    "\n",
    "# 6. TabNet 전용 설정 (cat_idxs, cat_dims)\n",
    "# [선택 이유] TabNet에게 어떤 컬럼이 '범주'이고, 그 범주에 몇 개의 종류가 있는지 알려줘야 \n",
    "# 내부 어텐션 메커니즘이 특성 선택을 올바르게 수행합니다.\n",
    "cat_idxs = [i for i, f in enumerate(feature_cols) if f in cat_cols]\n",
    "\n",
    "# [버그 수정] cat_dims를 train_df가 아닌 encoders의 클래스 개수로 설정해야 합니다.\n",
    "# train_df에 없는 카테고리가 valid/test에 있을 경우 IndexError가 발생하는 것을 방지합니다.\n",
    "cat_dims = [len(encoders[c].classes_) for c in cat_cols]\n",
    "\n",
    "# numpy 변환\n",
    "X_train = train_df[feature_cols].values\n",
    "y_train = train_df[TARGET].values.reshape(-1, 1)\n",
    "X_valid = valid_df[feature_cols].values\n",
    "y_valid = valid_df[TARGET].values.reshape(-1, 1)\n",
    "X_test  = test_df[feature_cols].values\n",
    "y_test  = test_df[TARGET].values.reshape(-1, 1)\n",
    "\n",
    "# 7. TabNetRegressor 모델 정의\n",
    "# [파라미터 선택 이유]\n",
    "model = TabNetRegressor(\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=8,         # [이유] 카테고리별로 8차원 공간에 정보를 압축 (팀, 포지션 의미 학습)\n",
    "    n_d=32, n_a=32,        # [이유] n_d(결정 단계 폭)와 n_a(어텐션 단계 폭)를 같게 설정하는 것이 논문 권장사항\n",
    "    n_steps=5,             # [이유] 의사결정 나무의 깊이와 유사한 개념. 5단계 정도로 충분히 복잡한 관계 학습\n",
    "    gamma=1.5,             # [이유] 특정 피처가 반복 선택되는 것을 제어하여 다양한 지표를 고루 보게 함\n",
    "    n_independent=2,       # [이유] 각 단계에서 독립적으로 학습할 레이어 수\n",
    "    n_shared=2,            # [이유] 모든 단계에서 공유할 레이어 수 (효율성 향상)\n",
    "    lambda_sparse=1e-4,    # [이유] 중요한 피처만 쓰도록 유도(Sparsity). 0에 가까울수록 모든 피처를 다 씀\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type=\"entmax\",     # [이유] sparsemax보다 더 명확하게 중요한 피처를 선택하는 경향이 있음\n",
    ")\n",
    "\n",
    "# 8. 모델 학습 (Fitting)\n",
    "# [선택 이유] virtual_batch_size는 Ghost Batch Normalization을 구현하며, \n",
    "# 데이터셋이 작을 때 과적합을 방지하고 학습을 안정화하는 핵심 요소입니다.\n",
    "model.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    eval_metric=[\"rmse\"],\n",
    "    max_epochs=200,\n",
    "    patience=30,           # [이유] 30번 동안 성능 개선 없으면 조기 종료 (Overfitting 방지)\n",
    "    batch_size=1024,       # [이유] 사용자의 4096보다 조금 줄여 야구 데이터 규모에 맞게 조정\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False\n",
    ")\n",
    "\n",
    "# 9. 평가 및 결과 출력\n",
    "preds = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, preds))\n",
    "r2 = r2_score(y_test, preds)\n",
    "\n",
    "print(\"\\n--- [학습 결과 보고서] ---\")\n",
    "print(f\"테스트 RMSE (오차): {rmse:.4f}\")\n",
    "print(f\"결정계수 R2 (설명력): {r2:.4f}\")\n",
    "\n",
    "# 10. 특성 중요도 (TabNet의 강점)\n",
    "# [이유] 어떤 타격 지표가 WAR 예측에 가장 기여했는지 확인 가능합니다.\n",
    "feat_importances = model.feature_importances_\n",
    "importance_df = pd.DataFrame({'feature': feature_cols, 'importance': feat_importances})\n",
    "print(\"\\n--- [상위 5개 중요 피처] ---\")\n",
    "print(importance_df.sort_values(by='importance', ascending=False).head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe5d7ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pytorch_tabnet/abstract_model.py:82: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 10005.96028| val_0_rmse: 88.94557|  0:00:00s\n",
      "epoch 1  | loss: 8456.7981| val_0_rmse: 507.16212|  0:00:00s\n",
      "epoch 2  | loss: 6609.12288| val_0_rmse: 147.84508|  0:00:01s\n",
      "epoch 3  | loss: 5345.89443| val_0_rmse: 468.14574|  0:00:01s\n",
      "epoch 4  | loss: 5289.63914| val_0_rmse: 778.71126|  0:00:02s\n",
      "epoch 5  | loss: 5174.815| val_0_rmse: 152.28337|  0:00:02s\n",
      "epoch 6  | loss: 5146.38786| val_0_rmse: 233.23023|  0:00:03s\n",
      "epoch 7  | loss: 5118.54032| val_0_rmse: 214.79689|  0:00:03s\n",
      "epoch 8  | loss: 5126.70539| val_0_rmse: 148.02118|  0:00:04s\n",
      "epoch 9  | loss: 5103.8097| val_0_rmse: 143.32856|  0:00:04s\n",
      "epoch 10 | loss: 5097.17608| val_0_rmse: 174.685 |  0:00:05s\n",
      "epoch 11 | loss: 5128.27207| val_0_rmse: 111.53207|  0:00:05s\n",
      "epoch 12 | loss: 5090.88491| val_0_rmse: 100.28361|  0:00:05s\n",
      "epoch 13 | loss: 5084.01503| val_0_rmse: 83.76698|  0:00:06s\n",
      "epoch 14 | loss: 5103.58109| val_0_rmse: 67.28873|  0:00:06s\n",
      "epoch 15 | loss: 5124.93574| val_0_rmse: 70.67712|  0:00:07s\n",
      "epoch 16 | loss: 5132.86875| val_0_rmse: 70.51215|  0:00:07s\n",
      "epoch 17 | loss: 5098.94864| val_0_rmse: 67.67923|  0:00:08s\n",
      "epoch 18 | loss: 5109.34557| val_0_rmse: 68.29918|  0:00:08s\n",
      "epoch 19 | loss: 5101.51312| val_0_rmse: 69.87323|  0:00:09s\n",
      "epoch 20 | loss: 5072.80922| val_0_rmse: 68.15937|  0:00:09s\n",
      "epoch 21 | loss: 5090.42059| val_0_rmse: 71.71848|  0:00:10s\n",
      "epoch 22 | loss: 5098.01203| val_0_rmse: 73.78539|  0:00:10s\n",
      "epoch 23 | loss: 5121.1382| val_0_rmse: 79.75805|  0:00:10s\n",
      "epoch 24 | loss: 5067.65427| val_0_rmse: 70.90424|  0:00:11s\n",
      "epoch 25 | loss: 5072.04209| val_0_rmse: 68.79797|  0:00:11s\n",
      "epoch 26 | loss: 5076.41507| val_0_rmse: 68.52654|  0:00:12s\n",
      "epoch 27 | loss: 5052.53388| val_0_rmse: 72.95445|  0:00:12s\n",
      "epoch 28 | loss: 5059.46313| val_0_rmse: 79.48491|  0:00:13s\n",
      "epoch 29 | loss: 5051.68734| val_0_rmse: 81.17005|  0:00:13s\n",
      "epoch 30 | loss: 5034.33908| val_0_rmse: 68.73347|  0:00:14s\n",
      "epoch 31 | loss: 5021.47841| val_0_rmse: 68.55771|  0:00:14s\n",
      "epoch 32 | loss: 5027.60515| val_0_rmse: 66.26859|  0:00:14s\n",
      "epoch 33 | loss: 5014.64331| val_0_rmse: 77.92658|  0:00:15s\n",
      "epoch 34 | loss: 5011.80867| val_0_rmse: 86.4334 |  0:00:15s\n",
      "epoch 35 | loss: 5034.70314| val_0_rmse: 81.80085|  0:00:16s\n",
      "epoch 36 | loss: 4994.97296| val_0_rmse: 66.81652|  0:00:16s\n",
      "epoch 37 | loss: 5013.27769| val_0_rmse: 71.74042|  0:00:17s\n",
      "epoch 38 | loss: 5021.02143| val_0_rmse: 66.41422|  0:00:17s\n",
      "epoch 39 | loss: 5020.6774| val_0_rmse: 69.57674|  0:00:18s\n",
      "epoch 40 | loss: 5009.05673| val_0_rmse: 67.96364|  0:00:18s\n",
      "epoch 41 | loss: 4991.33356| val_0_rmse: 68.36765|  0:00:19s\n",
      "epoch 42 | loss: 4996.21934| val_0_rmse: 69.39656|  0:00:19s\n",
      "epoch 43 | loss: 4988.69367| val_0_rmse: 69.71059|  0:00:20s\n",
      "epoch 44 | loss: 4986.32059| val_0_rmse: 67.28412|  0:00:20s\n",
      "epoch 45 | loss: 4975.80192| val_0_rmse: 68.84149|  0:00:20s\n",
      "epoch 46 | loss: 4941.1011| val_0_rmse: 67.24788|  0:00:21s\n",
      "epoch 47 | loss: 4923.21389| val_0_rmse: 67.5429 |  0:00:21s\n",
      "epoch 48 | loss: 4948.36009| val_0_rmse: 67.69361|  0:00:22s\n",
      "epoch 49 | loss: 4981.33675| val_0_rmse: 68.1588 |  0:00:22s\n",
      "epoch 50 | loss: 4951.76184| val_0_rmse: 66.59994|  0:00:23s\n",
      "epoch 51 | loss: 4959.42764| val_0_rmse: 66.64289|  0:00:23s\n",
      "epoch 52 | loss: 4985.72666| val_0_rmse: 67.03933|  0:00:24s\n",
      "epoch 53 | loss: 4979.07283| val_0_rmse: 67.71019|  0:00:24s\n",
      "epoch 54 | loss: 4988.15451| val_0_rmse: 66.3862 |  0:00:25s\n",
      "epoch 55 | loss: 4978.90843| val_0_rmse: 66.52706|  0:00:25s\n",
      "epoch 56 | loss: 4961.75448| val_0_rmse: 66.3389 |  0:00:25s\n",
      "epoch 57 | loss: 4992.08341| val_0_rmse: 65.67133|  0:00:26s\n",
      "epoch 58 | loss: 5045.69622| val_0_rmse: 67.01022|  0:00:26s\n",
      "epoch 59 | loss: 5015.33018| val_0_rmse: 66.46363|  0:00:27s\n",
      "epoch 60 | loss: 5012.09385| val_0_rmse: 66.3006 |  0:00:28s\n",
      "epoch 61 | loss: 5000.24235| val_0_rmse: 66.06707|  0:00:28s\n",
      "epoch 62 | loss: 4979.42032| val_0_rmse: 65.96503|  0:00:28s\n",
      "epoch 63 | loss: 5020.03807| val_0_rmse: 66.76288|  0:00:29s\n",
      "epoch 64 | loss: 5037.48068| val_0_rmse: 66.07718|  0:00:29s\n",
      "epoch 65 | loss: 4994.38062| val_0_rmse: 65.64284|  0:00:30s\n",
      "epoch 66 | loss: 5010.66682| val_0_rmse: 65.38137|  0:00:30s\n",
      "epoch 67 | loss: 4995.7159| val_0_rmse: 65.40534|  0:00:31s\n",
      "epoch 68 | loss: 5003.80239| val_0_rmse: 65.85805|  0:00:31s\n",
      "epoch 69 | loss: 5022.11475| val_0_rmse: 66.10517|  0:00:31s\n",
      "epoch 70 | loss: 4997.40627| val_0_rmse: 65.47431|  0:00:32s\n",
      "epoch 71 | loss: 4978.5121| val_0_rmse: 65.8729 |  0:00:32s\n",
      "epoch 72 | loss: 4977.50495| val_0_rmse: 65.35498|  0:00:33s\n",
      "epoch 73 | loss: 4972.80575| val_0_rmse: 65.88224|  0:00:33s\n",
      "epoch 74 | loss: 4958.29418| val_0_rmse: 65.46155|  0:00:34s\n",
      "epoch 75 | loss: 4970.13976| val_0_rmse: 66.35988|  0:00:34s\n",
      "epoch 76 | loss: 4948.48751| val_0_rmse: 66.33678|  0:00:35s\n",
      "epoch 77 | loss: 4953.27609| val_0_rmse: 66.52779|  0:00:35s\n",
      "epoch 78 | loss: 4929.12767| val_0_rmse: 66.01975|  0:00:36s\n",
      "epoch 79 | loss: 4923.44622| val_0_rmse: 66.25768|  0:00:36s\n",
      "epoch 80 | loss: 4936.67874| val_0_rmse: 66.20247|  0:00:37s\n",
      "epoch 81 | loss: 4945.06236| val_0_rmse: 66.52031|  0:00:37s\n",
      "epoch 82 | loss: 4948.64394| val_0_rmse: 66.29137|  0:00:38s\n",
      "epoch 83 | loss: 4966.0371| val_0_rmse: 65.16687|  0:00:38s\n",
      "epoch 84 | loss: 4960.1376| val_0_rmse: 65.59526|  0:00:38s\n",
      "epoch 85 | loss: 4967.03668| val_0_rmse: 66.0575 |  0:00:39s\n",
      "epoch 86 | loss: 4960.38856| val_0_rmse: 65.97941|  0:00:39s\n",
      "epoch 87 | loss: 4952.38782| val_0_rmse: 66.75721|  0:00:40s\n",
      "epoch 88 | loss: 4987.09651| val_0_rmse: 66.94689|  0:00:40s\n",
      "epoch 89 | loss: 4970.61261| val_0_rmse: 66.2162 |  0:00:41s\n",
      "epoch 90 | loss: 4980.07447| val_0_rmse: 66.45948|  0:00:41s\n",
      "epoch 91 | loss: 4970.67056| val_0_rmse: 66.43147|  0:00:42s\n",
      "epoch 92 | loss: 4948.28647| val_0_rmse: 66.42731|  0:00:42s\n",
      "epoch 93 | loss: 4933.9422| val_0_rmse: 66.10072|  0:00:42s\n",
      "epoch 94 | loss: 4916.83508| val_0_rmse: 65.93823|  0:00:43s\n",
      "epoch 95 | loss: 4928.79076| val_0_rmse: 66.75681|  0:00:43s\n",
      "epoch 96 | loss: 4922.5954| val_0_rmse: 65.97283|  0:00:44s\n",
      "epoch 97 | loss: 4900.8298| val_0_rmse: 66.14422|  0:00:44s\n",
      "epoch 98 | loss: 4921.40177| val_0_rmse: 66.7316 |  0:00:45s\n",
      "epoch 99 | loss: 4922.24602| val_0_rmse: 66.54519|  0:00:45s\n",
      "epoch 100| loss: 4924.86352| val_0_rmse: 65.93473|  0:00:46s\n",
      "epoch 101| loss: 4969.02118| val_0_rmse: 66.77245|  0:00:46s\n",
      "epoch 102| loss: 4929.67982| val_0_rmse: 66.35344|  0:00:47s\n",
      "epoch 103| loss: 4941.80953| val_0_rmse: 66.06106|  0:00:47s\n",
      "epoch 104| loss: 4945.33985| val_0_rmse: 66.56235|  0:00:47s\n",
      "epoch 105| loss: 4909.24899| val_0_rmse: 66.71782|  0:00:48s\n",
      "epoch 106| loss: 4902.25219| val_0_rmse: 66.5794 |  0:00:48s\n",
      "epoch 107| loss: 4902.76136| val_0_rmse: 65.93629|  0:00:49s\n",
      "epoch 108| loss: 4900.51421| val_0_rmse: 66.36817|  0:00:49s\n",
      "epoch 109| loss: 4920.95446| val_0_rmse: 66.63831|  0:00:50s\n",
      "epoch 110| loss: 4902.01559| val_0_rmse: 66.82399|  0:00:50s\n",
      "epoch 111| loss: 4877.43793| val_0_rmse: 67.11881|  0:00:51s\n",
      "epoch 112| loss: 4898.23473| val_0_rmse: 66.88409|  0:00:51s\n",
      "epoch 113| loss: 4864.6961| val_0_rmse: 66.85016|  0:00:52s\n",
      "\n",
      "Early stopping occurred at epoch 113 with best_epoch = 83 and best_val_0_rmse = 65.16687\n",
      "\n",
      "--- [테스트(2024 -> 2025) 성능] ---\n",
      "RMSE: 71.2891\n",
      "R2  : 0.0632\n",
      "\n",
      "--- [2026 WAR 예측 결과: 상위 20명] ---\n",
      "   Id  Year  Team  Age  WAR_2026_pred\n",
      "10261  2025     4   37      96.163330\n",
      "12534  2025     0   28      82.799446\n",
      "14606  2025     1   28      68.411026\n",
      "14612  2025     0   25      61.173042\n",
      "11099  2025     0   31      52.245850\n",
      "11153  2025     4   32      39.672276\n",
      "16344  2025     4   19      -3.028098\n",
      "\n",
      "--- [상위 10개 중요 피처] ---\n",
      "feature  importance\n",
      "    RBI    0.170314\n",
      "     BB    0.114649\n",
      "    OBP    0.114413\n",
      "     TB    0.103580\n",
      "2B_isna    0.061892\n",
      "    SLG    0.044069\n",
      "     AB    0.040914\n",
      "BB_isna    0.036167\n",
      "   Year    0.031285\n",
      "     SF    0.030057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/pytorch_tabnet/callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "# 정상 동작 버전(수정): 문자열 dtype 때문에 median()이 깨지는 문제 해결 포함\n",
    "# - 핵심 수정 1) USE_NAME=False일 때 Name을 feature에서 제거\n",
    "# - 핵심 수정 2) 수치형 결측 처리 전에 non-cat 컬럼을 강제로 to_numeric(coerce)\n",
    "# - 핵심 수정 3) 중앙값은 numeric dtype에서만 계산(안전장치)\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "\n",
    "\n",
    "def seed_everything(seed: int = 42):\n",
    "    import random\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(42)\n",
    "\n",
    "# 1) 로드\n",
    "df = pd.read_csv(\"data/raw/kbo_batting_stats_by_season_1982-2025.csv\")\n",
    "\n",
    "# 2) 기본 정리: 필요한 컬럼 확인 및 숫자 변환\n",
    "# 문자열 컬럼(범주/텍스트) 목록\n",
    "TEXT_COLS = {\"Name\", \"Birthdate\", \"Handedness\", \"School\", \"Draft\", \"Team\", \"Pos.\"}\n",
    "\n",
    "# 숫자형으로 바뀌어야 하는 컬럼들은 가능한 한 전부 변환(실패는 NaN)\n",
    "for c in df.columns:\n",
    "    if c in TEXT_COLS:\n",
    "        continue\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "\n",
    "# 필수 컬럼\n",
    "df = df.dropna(subset=[\"Id\", \"Year\", \"wRC+\"]).copy()\n",
    "\n",
    "# shift를 위해 정렬\n",
    "df = df.sort_values([\"Id\", \"Year\"]).reset_index(drop=True)\n",
    "\n",
    "# 3) 타겟: 다음 시즌 WAR\n",
    "df[\"wRC+_next\"] = df.groupby(\"Id\")[\"wRC+\"].shift(-1)\n",
    "\n",
    "df = df.dropna(subset=[\"wRC+_next\"]).copy()\n",
    "TARGET = \"wRC+_next\"\n",
    "\n",
    "# 4) 누수/중복 컬럼 제거(권장)\n",
    "drop_cols = [\"Birthdate\", \"School\", \"Draft\", \"oWAR\", \"dWAR\", \"WAR\"]\n",
    "df = df.drop(columns=[c for c in drop_cols if c in df.columns])\n",
    "\n",
    "# 5) 범주형 컬럼 구성\n",
    "USE_NAME = False  # True로 하면 Name을 범주로 사용(암기 성향 강해짐)\n",
    "\n",
    "cat_cols = [\"Handedness\", \"Team\", \"Pos.\"]\n",
    "if USE_NAME and \"Name\" in df.columns:\n",
    "    cat_cols = [\"Name\"] + cat_cols\n",
    "cat_cols = [c for c in cat_cols if c in df.columns]\n",
    "\n",
    "# 6) 피처 컬럼 선택\n",
    "#  - TARGET은 제외\n",
    "#  - 현재 시즌 WAR는(강한 힌트) 기본 제외\n",
    "EXCLUDE_FROM_FEATURES = {TARGET, \"wRC+\"}\n",
    "\n",
    "# USE_NAME=False면 Name은 피처에서 완전히 제외(중요!)\n",
    "if (not USE_NAME) and (\"Name\" in df.columns):\n",
    "    EXCLUDE_FROM_FEATURES.add(\"Name\")\n",
    "\n",
    "feature_cols = [c for c in df.columns if c not in EXCLUDE_FROM_FEATURES]\n",
    "\n",
    "# 7) 시계열 분할(X의 Year 기준)\n",
    "train_df = df[df[\"Year\"] <= 2022].copy()\n",
    "valid_df = df[df[\"Year\"] == 2023].copy()\n",
    "test_df  = df[df[\"Year\"] == 2024].copy()   # 평가용(정답=2025 WAR)\n",
    "pred_df  = df[df[\"Year\"] == 2025].copy()   # 2026 예측용(정답 없음)\n",
    "\n",
    "# 8) 누수 없는 범주 인코딩 + UNK 처리\n",
    "class SafeLabelEncoder:\n",
    "    def __init__(self, unk_token=\"__UNK__\"):\n",
    "        self.unk_token = unk_token\n",
    "        self.le = LabelEncoder()\n",
    "        self.known = None\n",
    "\n",
    "    def fit(self, s: pd.Series):\n",
    "        vals = s.astype(str).fillna(\"NA\").values\n",
    "        vals = np.concatenate([vals, np.array([self.unk_token])])\n",
    "        self.le.fit(vals)\n",
    "        self.known = set(self.le.classes_)\n",
    "        return self\n",
    "\n",
    "    def transform(self, s: pd.Series) -> np.ndarray:\n",
    "        vals = s.astype(str).fillna(\"NA\").values\n",
    "        vals = np.array([v if v in self.known else self.unk_token for v in vals], dtype=object)\n",
    "        return self.le.transform(vals)\n",
    "\n",
    "    @property\n",
    "    def classes_(self):\n",
    "        return self.le.classes_\n",
    "\n",
    "encoders = {}\n",
    "for c in cat_cols:\n",
    "    enc = SafeLabelEncoder().fit(train_df[c])  # train만 fit\n",
    "    encoders[c] = enc\n",
    "\n",
    "    train_df[c] = enc.transform(train_df[c])\n",
    "    valid_df[c] = enc.transform(valid_df[c])\n",
    "    if len(test_df) > 0:\n",
    "        test_df[c]  = enc.transform(test_df[c])\n",
    "    if len(pred_df) > 0:\n",
    "        pred_df[c]  = enc.transform(pred_df[c])\n",
    "\n",
    "# 9) 수치형 결측 처리: median() 오류 방지\n",
    "ADD_MISSING_INDICATORS = True\n",
    "\n",
    "# feature_cols를 복사해 두고, indicator 추가는 별도 리스트에 누적 후 마지막에 확장(루프 중 append 위험 제거)\n",
    "missing_indicators = []\n",
    "\n",
    "for c in feature_cols:\n",
    "    if c in cat_cols:\n",
    "        continue\n",
    "\n",
    "    # ★핵심: 수치형으로 강제 변환(문자열이면 NaN으로 바뀜)\n",
    "    for dset in [train_df, valid_df, test_df, pred_df]:\n",
    "        if len(dset) == 0:\n",
    "            continue\n",
    "        dset[c] = pd.to_numeric(dset[c], errors=\"coerce\")\n",
    "\n",
    "    if ADD_MISSING_INDICATORS:\n",
    "        ind_col = f\"{c}_isna\"\n",
    "        missing_indicators.append(ind_col)\n",
    "        for dset in [train_df, valid_df, test_df, pred_df]:\n",
    "            if len(dset) == 0:\n",
    "                continue\n",
    "            dset[ind_col] = dset[c].isna().astype(int)\n",
    "\n",
    "    # 중앙값 계산은 numeric에서만 수행\n",
    "    if not pd.api.types.is_numeric_dtype(train_df[c]):\n",
    "        # 여기까지 왔는데도 numeric이 아니면, 안전하게 스킵\n",
    "        # (실제로는 위 to_numeric로 대부분 해결됩니다)\n",
    "        continue\n",
    "\n",
    "    median_val = train_df[c].median(skipna=True)\n",
    "    for dset in [train_df, valid_df, test_df, pred_df]:\n",
    "        if len(dset) == 0:\n",
    "            continue\n",
    "        dset[c] = dset[c].fillna(median_val)\n",
    "\n",
    "# indicator들을 feature_cols에 마지막에 추가\n",
    "for ind_col in missing_indicators:\n",
    "    if ind_col not in feature_cols:\n",
    "        feature_cols.append(ind_col)\n",
    "\n",
    "# 10) TabNet cat 설정(순서 정렬 필수)\n",
    "ordered_cat_cols = [f for f in feature_cols if f in cat_cols]\n",
    "cat_idxs = [feature_cols.index(c) for c in ordered_cat_cols]\n",
    "cat_dims = [len(encoders[c].classes_) for c in ordered_cat_cols]\n",
    "\n",
    "# 11) numpy 변환\n",
    "X_train = train_df[feature_cols].values\n",
    "X_valid = valid_df[feature_cols].values\n",
    "\n",
    "y_train = train_df[TARGET].values.reshape(-1, 1)\n",
    "y_valid = valid_df[TARGET].values.reshape(-1, 1)\n",
    "\n",
    "X_test = y_test = None\n",
    "if len(test_df) > 0:\n",
    "    X_test = test_df[feature_cols].values\n",
    "    y_test = test_df[TARGET].values.reshape(-1, 1)\n",
    "\n",
    "X_pred = None\n",
    "if len(pred_df) > 0:\n",
    "    X_pred = pred_df[feature_cols].values\n",
    "\n",
    "# 12) 모델\n",
    "model = TabNetRegressor(\n",
    "    cat_idxs=cat_idxs if len(cat_idxs) > 0 else [],\n",
    "    cat_dims=cat_dims if len(cat_dims) > 0 else [],\n",
    "    cat_emb_dim=8,\n",
    "    n_d=32, n_a=32,\n",
    "    n_steps=5,\n",
    "    gamma=1.5,\n",
    "    n_independent=2,\n",
    "    n_shared=2,\n",
    "    lambda_sparse=1e-4,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=2e-2),\n",
    "    mask_type=\"entmax\",\n",
    ")\n",
    "\n",
    "# 13) 학습\n",
    "model.fit(\n",
    "    X_train=X_train, y_train=y_train,\n",
    "    eval_set=[(X_valid, y_valid)],\n",
    "    eval_metric=[\"rmse\"],\n",
    "    max_epochs=200,\n",
    "    patience=30,\n",
    "    batch_size=1024,\n",
    "    virtual_batch_size=128,\n",
    "    num_workers=0,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "# 14) 평가(2024 -> 2025)\n",
    "if X_test is not None:\n",
    "    preds_test = model.predict(X_test)\n",
    "    rmse = float(np.sqrt(mean_squared_error(y_test, preds_test)))\n",
    "    r2 = float(r2_score(y_test, preds_test))\n",
    "    print(\"\\n--- [테스트(2024 -> 2025) 성능] ---\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R2  : {r2:.4f}\")\n",
    "\n",
    "# 15) 2026 예측(2025 -> 2026)\n",
    "if X_pred is not None and len(pred_df) > 0:\n",
    "    preds_2026 = model.predict(X_pred).reshape(-1)\n",
    "\n",
    "    # 결과 리포팅(원래 문자열 컬럼은 df에서 유지되어 있을 수 있음)\n",
    "    # pred_df에서 Name을 제외했더라도, 원 df와 merge해서 출력할 수도 있습니다.\n",
    "    report_cols = [c for c in [\"Id\", \"Year\", \"Team\", \"Age\"] if c in pred_df.columns]\n",
    "    out = pred_df[report_cols].copy()\n",
    "    out[\"WAR_2026_pred\"] = preds_2026\n",
    "\n",
    "    print(\"\\n--- [2026 WAR 예측 결과: 상위 20명] ---\")\n",
    "    print(out.sort_values(\"WAR_2026_pred\", ascending=False).head(20).to_string(index=False))\n",
    "\n",
    "# 16) 중요도\n",
    "feat_importances = model.feature_importances_\n",
    "importance_df = pd.DataFrame({\"feature\": feature_cols, \"importance\": feat_importances})\n",
    "print(\"\\n--- [상위 10개 중요 피처] ---\")\n",
    "print(importance_df.sort_values(\"importance\", ascending=False).head(10).to_string(index=False))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
