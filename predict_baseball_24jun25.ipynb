{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65e85411",
   "metadata": {},
   "source": [
    "### References \n",
    "1. Purucker, M. C.. “Neural network quarterbacking.” IEEE Potentials 15 (1996): 9-15.\n",
    "2. PREDICTING MLB GAMES USING A MULTILAYER PERCEPTRON NEURAL NETWORK, RYAN LEWIS, MAY 1, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6fe0437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4742179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "[STEP 1] Load data\n",
      "======================================================================\n",
      "Input: 3 CSV files (scoreboard, batter, pitcher)\n",
      "Expected Output: DataFrames created for all 3 files\n",
      "Real Output:\n",
      "  - scoreboard shape: (2434, 37), columns: ['idx', 'team', 'result', 'i_1', 'i_2']\n",
      "  - batter shape: (31465, 26), columns: ['idx', 'name', 'team', 'position', 'i_1']\n",
      "  - pitcher shape: (11983, 15), columns: ['idx', 'name', 'team', 'mound', 'inning']\n",
      "\n",
      "======================================================================\n",
      "[STEP 2] Sort by date and binarize win flag\n",
      "======================================================================\n",
      "Input: scoreboard DataFrame (before sort)\n",
      "Expected Output: date-sorted DataFrame + win_binary column\n",
      "Real Output:\n",
      "  - scoreboard shape: (2434, 38)\n",
      "  - win_binary distribution: {0: 1247, 1: 1187}\n",
      "  - sample:\n",
      "   year  month  day  result  win_binary\n",
      "0  2024      6    1       1           1\n",
      "1  2024      6    1      -1           0\n",
      "4  2024      6    1      -1           0\n",
      "5  2024      6    1       1           1\n",
      "6  2024      6    1      -1           0\n",
      "\n",
      "======================================================================\n",
      "[STEP 3] Aggregate batter data to team totals per game\n",
      "======================================================================\n",
      "Input: batter DataFrame shape (31465, 26)\n",
      "Expected Output: hit and bat_num summed by idx\n",
      "Real Output:\n",
      "  - team_batting shape: (2434, 3)\n",
      "  - hit stats: min=0, max=28, mean=9.17\n",
      "  - sample:\n",
      "           idx  hit  bat_num\n",
      "0  20240601001   10       40\n",
      "1  20240601002    7       30\n",
      "2  20240601003    8       30\n",
      "3  20240601004    6       33\n",
      "4  20240601005   14       44\n",
      "\n",
      "======================================================================\n",
      "[STEP 4] Join base game info with team batting data\n",
      "======================================================================\n",
      "Input: scoreboard columns + team_batting\n",
      "Expected Output: DataFrame merged on idx\n",
      "Real Output:\n",
      "  - base_df shape: (2434, 12)\n",
      "  - columns: ['idx', 'team', 'year', 'month', 'day', 'home', 'away', 'r', 'win_binary', 'dbheader', 'hit', 'bat_num']\n",
      "  - sample:\n",
      "           idx team  hit  bat_num\n",
      "0  20240601005   LG   14       44\n",
      "1  20240601001   두산   10       40\n",
      "2  20240601004   한화    6       33\n",
      "3  20240601003   삼성    8       30\n",
      "4  20240601010   KT    5       31\n",
      "\n",
      "======================================================================\n",
      "[STEP 5] Create game_id (with doubleheader)\n",
      "======================================================================\n",
      "Input: year, month, day, home, away, dbheader\n",
      "Expected Output: game_id formatted as YYYYMMDD_HOME_AWAY_DBHEADER\n",
      "Real Output:\n",
      "  - game_id sample: ['20240601_두산_LG_0', '20240601_두산_LG_0', '20240601_삼성_한화_0']\n",
      "  - unique games: 1217\n",
      "\n",
      "======================================================================\n",
      "[STEP 6] Match opponent runs allowed\n",
      "======================================================================\n",
      "Input: base_df game_id, team, r\n",
      "Expected Output: two rows per game (home/away) with runs_allowed\n",
      "Real Output:\n",
      "  - base_df shape (after filter): (2434, 15)\n",
      "  - runs_allowed stats: min=0, max=30, mean=4.97\n",
      "  - sample:\n",
      "             game_id team opp_team  r  runs_allowed\n",
      "1   20240601_두산_LG_0   LG       두산  8             5\n",
      "2   20240601_두산_LG_0   두산       LG  5             8\n",
      "5   20240601_삼성_한화_0   한화       삼성  4             6\n",
      "6   20240601_삼성_한화_0   삼성       한화  6             4\n",
      "9  20240601_KIA_KT_0   KT      KIA  2             4\n",
      "\n",
      "======================================================================\n",
      "[STEP 7-1] Rolling average over last 30 games (runs scored/allowed)\n",
      "======================================================================\n",
      "Input: team-sorted r and runs_allowed\n",
      "Expected Output: mean runs scored/allowed over last 30 games (NaN allowed)\n",
      "Real Output:\n",
      "  - f1_avg_runs_scored_30: NaN=10, min=0.00, max=9.00\n",
      "  - f2_avg_runs_allowed_30: NaN=10, min=0.00, max=9.00\n",
      "  - sample:\n",
      "    team  f1_avg_runs_scored_30  f2_avg_runs_allowed_30\n",
      "10   KIA                    NaN                     NaN\n",
      "34   KIA               4.000000                2.000000\n",
      "58   KIA               3.500000                6.500000\n",
      "78   KIA               2.333333                6.333333\n",
      "86   KIA               2.500000                7.000000\n",
      "109  KIA               3.000000                6.400000\n",
      "121  KIA               3.333333                6.333333\n",
      "149  KIA               4.000000                6.714286\n",
      "161  KIA               4.500000                6.125000\n",
      "185  KIA               4.666667                6.222222\n",
      "\n",
      "======================================================================\n",
      "[STEP 7-2] Team batting average over last 30 games\n",
      "======================================================================\n",
      "Input: 30-game rolling sums of team hit and bat_num\n",
      "Expected Output: team batting average = rolling_hits / rolling_ab\n",
      "Real Output:\n",
      "  - f3_team_batting_avg_30: NaN=10, min=0.1613, max=0.3614\n",
      "  - sample:\n",
      "    team  hit  bat_num  f3_team_batting_avg_30\n",
      "10   KIA   11       34                     NaN\n",
      "34   KIA    7       34                0.323529\n",
      "58   KIA    5       31                0.264706\n",
      "78   KIA    7       34                0.232323\n",
      "86   KIA    7       30                0.225564\n",
      "109  KIA   15       46                0.226994\n",
      "121  KIA   15       40                0.248804\n",
      "149  KIA   11       37                0.269076\n",
      "161  KIA   14       42                0.272727\n",
      "185  KIA   16       42                0.280488\n",
      "\n",
      "======================================================================\n",
      "[STEP 8] Starting pitcher season average runs allowed\n",
      "======================================================================\n",
      "Input: pitcher data (filtered to mound==1)\n",
      "Expected Output: cumulative mean runs allowed per pitcher (expanding mean)\n",
      "Real Output:\n",
      "  - starters shape: (2434, 7)\n",
      "  - f4_pitcher_runs_avg: NaN=162, min=0.00, max=10.00\n",
      "  - sample:\n",
      "      name  losescore  f4_pitcher_runs_avg\n",
      "2074  가라비토          0                  NaN\n",
      "1320  가라비토          1             0.000000\n",
      "1348  가라비토          4             0.500000\n",
      "2154  가라비토          0             1.666667\n",
      "1404  가라비토          0             1.250000\n",
      "2204  가라비토          4             1.000000\n",
      "1449  가라비토          3             1.500000\n",
      "1469  가라비토          3             1.714286\n",
      "1493  가라비토          5             1.875000\n",
      "1517  가라비토          1             2.222222\n",
      "\n",
      "======================================================================\n",
      "[STEP 8-2] Add pitcher info to base_df\n",
      "======================================================================\n",
      "Input: base_df + starters f4_pitcher_runs_avg\n",
      "Expected Output: merge on idx\n",
      "Real Output:\n",
      "  - base_df shape: (2434, 19)\n",
      "  - f4_pitcher_runs_avg: NaN=162\n",
      "\n",
      "======================================================================\n",
      "[STEP 9] Team overall win rate\n",
      "======================================================================\n",
      "Input: team win_binary\n",
      "Expected Output: cumulative win rate (expanding mean)\n",
      "Real Output:\n",
      "  - f5_total_win_pct: NaN=10, min=0.0000, max=1.0000\n",
      "  - sample:\n",
      "  team  win_binary  f5_total_win_pct\n",
      "0  KIA           1               NaN\n",
      "1  KIA           0          1.000000\n",
      "2  KIA           0          0.500000\n",
      "3  KIA           0          0.333333\n",
      "4  KIA           1          0.250000\n",
      "5  KIA           0          0.400000\n",
      "6  KIA           0          0.333333\n",
      "7  KIA           1          0.285714\n",
      "8  KIA           0          0.375000\n",
      "9  KIA           1          0.333333\n",
      "\n",
      "======================================================================\n",
      "[STEP 10] Home/away win rate\n",
      "======================================================================\n",
      "Input: team and is_home (home/away flag)\n",
      "Expected Output: cumulative win rate by team-is_home\n",
      "Real Output:\n",
      "  - f6_ha_win_pct: NaN=20, min=0.0000, max=1.0000\n",
      "  - is_home distribution: {True: 1217, False: 1217}\n",
      "  - sample:\n",
      "  team  is_home  win_binary  f6_ha_win_pct\n",
      "0  KIA     True           1            NaN\n",
      "1  KIA     True           0       1.000000\n",
      "2  KIA     True           0       0.500000\n",
      "3  KIA     True           0       0.333333\n",
      "4  KIA     True           1       0.250000\n",
      "5  KIA    False           0            NaN\n",
      "6  KIA    False           0       0.000000\n",
      "7  KIA    False           1       0.000000\n",
      "8  KIA    False           0       0.333333\n",
      "9  KIA    False           1       0.250000\n",
      "\n",
      "======================================================================\n",
      "[STEP 11-1] Split home/away data\n",
      "======================================================================\n",
      "Input: all game records in base_df\n",
      "Expected Output: separate rows for home and away teams\n",
      "Real Output:\n",
      "  - home_df shape: (1217, 8)\n",
      "  - away_df shape: (1217, 7)\n",
      "  - home_df sample:\n",
      "             game_id  home_win  h_f1_avg_runs_scored_30  \\\n",
      "0  20240601_KIA_KT_0         1                      NaN   \n",
      "1  20240602_KIA_KT_0         0                 4.000000   \n",
      "2  20240604_KIA_롯데_0         0                 3.500000   \n",
      "3  20240605_KIA_롯데_0         0                 2.333333   \n",
      "4  20240606_KIA_롯데_0         1                 2.500000   \n",
      "\n",
      "   h_f2_avg_runs_allowed_30  h_f3_team_batting_avg_30  h_f4_pitcher_runs_avg  \\\n",
      "0                       NaN                       NaN                    NaN   \n",
      "1                  2.000000                  0.323529                    NaN   \n",
      "2                  6.500000                  0.264706                    NaN   \n",
      "3                  6.333333                  0.232323                    NaN   \n",
      "4                  7.000000                  0.225564                    NaN   \n",
      "\n",
      "   h_f5_total_win_pct  h_f6_ha_win_pct  \n",
      "0                 NaN              NaN  \n",
      "1            1.000000         1.000000  \n",
      "2            0.500000         0.500000  \n",
      "3            0.333333         0.333333  \n",
      "4            0.250000         0.250000  \n",
      "  - away_df sample:\n",
      "              game_id  a_f1_avg_runs_scored_30  a_f2_avg_runs_allowed_30  \\\n",
      "5   20240607_두산_KIA_0                 3.000000                  6.400000   \n",
      "6   20240608_두산_KIA_0                 3.333333                  6.333333   \n",
      "7   20240609_두산_KIA_0                 4.000000                  6.714286   \n",
      "8  20240611_SSG_KIA_0                 4.500000                  6.125000   \n",
      "9  20240612_SSG_KIA_0                 4.666667                  6.222222   \n",
      "\n",
      "   a_f3_team_batting_avg_30  a_f4_pitcher_runs_avg  a_f5_total_win_pct  \\\n",
      "5                  0.226994                    1.0            0.400000   \n",
      "6                  0.248804                    NaN            0.333333   \n",
      "7                  0.269076                    4.0            0.285714   \n",
      "8                  0.272727                    3.0            0.375000   \n",
      "9                  0.280488                    3.0            0.333333   \n",
      "\n",
      "   a_f6_ha_win_pct  \n",
      "5              NaN  \n",
      "6         0.000000  \n",
      "7         0.000000  \n",
      "8         0.333333  \n",
      "9         0.250000  \n",
      "\n",
      "======================================================================\n",
      "[STEP 11-2] Merge home/away data and drop NaN\n",
      "======================================================================\n",
      "Input: home_df, away_df (on game_id)\n",
      "Expected Output: rows with both home/away features per game_id\n",
      "Real Output:\n",
      "  - rows before merge: 1217\n",
      "  - rows after merge (before dropna): 1217\n",
      "  - final_dataset shape (after dropna): (1085, 14)\n",
      "  - columns: ['game_id', 'home_win', 'h_f1_avg_runs_scored_30', 'h_f2_avg_runs_allowed_30', 'h_f3_team_batting_avg_30', 'h_f4_pitcher_runs_avg', 'h_f5_total_win_pct', 'h_f6_ha_win_pct', 'a_f1_avg_runs_scored_30', 'a_f2_avg_runs_allowed_30', 'a_f3_team_batting_avg_30', 'a_f4_pitcher_runs_avg', 'a_f5_total_win_pct', 'a_f6_ha_win_pct']\n",
      "\n",
      "======================================================================\n",
      "[STEP 12] Create target label\n",
      "======================================================================\n",
      "Input: home_win (home win=1, away win=0)\n",
      "Expected Output: target (home win=0, away win=1)\n",
      "Real Output:\n",
      "  - target distribution: {1: 543, 0: 542}\n",
      "  - target ratio: home wins (0)=49.95%, away wins (1)=50.05%\n",
      "  - sample:\n",
      "             game_id  target\n",
      "5  20240618_KIA_LG_0       0\n",
      "6  20240619_KIA_LG_0       1\n",
      "7  20240620_KIA_LG_0       0\n",
      "8  20240621_KIA_한화_0       0\n",
      "9  20240623_KIA_한화_1       1\n",
      "\n",
      "======================================================================\n",
      "[STEP 13] Save final dataset\n",
      "======================================================================\n",
      "Input: final_dataset\n",
      "Expected Output: kbo_mlp_training_data.csv saved\n",
      "Real Output:\n",
      "  - filename: kbo_mlp_training_data.csv\n",
      "  - final shape: (1085, 14)\n",
      "  - column count: 14\n",
      "  - columns: ['game_id', 'h_f1_avg_runs_scored_30', 'h_f2_avg_runs_allowed_30', 'h_f3_team_batting_avg_30', 'h_f4_pitcher_runs_avg', 'h_f5_total_win_pct', 'h_f6_ha_win_pct', 'a_f1_avg_runs_scored_30', 'a_f2_avg_runs_allowed_30', 'a_f3_team_batting_avg_30', 'a_f4_pitcher_runs_avg', 'a_f5_total_win_pct', 'a_f6_ha_win_pct', 'target']\n",
      "\n",
      "Training dataset built: 1085 games included\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# 1. Load data\n",
    "sb = pd.read_csv('csv/scoreboard_2024_06_2025.csv')\n",
    "bt = pd.read_csv('csv/batter_2024_06_2025.csv')\n",
    "pt = pd.read_csv('csv/pitcher_2024_06_2025.csv')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 1] Load data\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: 3 CSV files (scoreboard, batter, pitcher)\")\n",
    "print(f\"Expected Output: DataFrames created for all 3 files\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - scoreboard shape: {sb.shape}, columns: {list(sb.columns[:5])}\")\n",
    "print(f\"  - batter shape: {bt.shape}, columns: {list(bt.columns[:5])}\")\n",
    "print(f\"  - pitcher shape: {pt.shape}, columns: {list(pt.columns[:5])}\")\n",
    "print()\n",
    "\n",
    "# Sort by date and binarize win flag\n",
    "sb = sb.sort_values(['year', 'month', 'day', 'starttime'])\n",
    "sb['win_binary'] = (sb['result'] == 1).astype(int)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 2] Sort by date and binarize win flag\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: scoreboard DataFrame (before sort)\")\n",
    "print(f\"Expected Output: date-sorted DataFrame + win_binary column\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - scoreboard shape: {sb.shape}\")\n",
    "print(f\"  - win_binary distribution: {sb['win_binary'].value_counts().to_dict()}\")\n",
    "print(f\"  - sample:\\n{sb[['year', 'month', 'day', 'result', 'win_binary']].head()}\")\n",
    "print()\n",
    "\n",
    "# 2. Aggregate batter data to team totals per game (idx)\n",
    "team_batting = bt.groupby('idx').agg({\n",
    "    'hit': 'sum',\n",
    "    'bat_num': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 3] Aggregate batter data to team totals per game\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: batter DataFrame shape {bt.shape}\")\n",
    "print(f\"Expected Output: hit and bat_num summed by idx\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - team_batting shape: {team_batting.shape}\")\n",
    "print(f\"  - hit stats: min={team_batting['hit'].min()}, max={team_batting['hit'].max()}, mean={team_batting['hit'].mean():.2f}\")\n",
    "print(f\"  - sample:\\n{team_batting.head()}\")\n",
    "print()\n",
    "\n",
    "# Join with base game info\n",
    "base_df = pd.merge(sb[['idx', 'team', 'year', 'month', 'day', 'home', 'away', 'r', 'win_binary', 'dbheader']], \n",
    "                   team_batting, on='idx', how='left')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 4] Join base game info with team batting data\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: scoreboard columns + team_batting\")\n",
    "print(f\"Expected Output: DataFrame merged on idx\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - base_df shape: {base_df.shape}\")\n",
    "print(f\"  - columns: {list(base_df.columns)}\")\n",
    "print(f\"  - sample:\\n{base_df[['idx', 'team', 'hit', 'bat_num']].head()}\")\n",
    "print()\n",
    "\n",
    "# 3. Match opponent runs scored/allowed (includes doubleheader dbheader)\n",
    "# Add dbheader into game_id to distinguish doubleheaders.\n",
    "base_df['game_id'] = (base_df['year'].astype(str) + \n",
    "                     base_df['month'].astype(str).str.zfill(2) + \n",
    "                     base_df['day'].astype(str).str.zfill(2) + \"_\" + \n",
    "                     base_df['home'] + \"_\" + base_df['away'] + \"_\" + \n",
    "                     base_df['dbheader'].astype(str))\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 5] Create game_id (with doubleheader)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: year, month, day, home, away, dbheader\")\n",
    "print(f\"Expected Output: game_id formatted as YYYYMMDD_HOME_AWAY_DBHEADER\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - game_id sample: {base_df['game_id'].iloc[:3].tolist()}\")\n",
    "print(f\"  - unique games: {base_df['game_id'].nunique()}\")\n",
    "print()\n",
    "\n",
    "opp_scores = base_df[['game_id', 'team', 'r']].rename(columns={'team': 'opp_team', 'r': 'runs_allowed'})\n",
    "base_df = pd.merge(base_df, opp_scores, on='game_id')\n",
    "base_df = base_df[base_df['team'] != base_df['opp_team']].copy()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 6] Match opponent runs allowed\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: base_df game_id, team, r\")\n",
    "print(f\"Expected Output: two rows per game (home/away) with runs_allowed\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - base_df shape (after filter): {base_df.shape}\")\n",
    "print(f\"  - runs_allowed stats: min={base_df['runs_allowed'].min()}, max={base_df['runs_allowed'].max()}, mean={base_df['runs_allowed'].mean():.2f}\")\n",
    "print(f\"  - sample:\\n{base_df[['game_id', 'team', 'opp_team', 'r', 'runs_allowed']].head()}\")\n",
    "print()\n",
    "\n",
    "# 4. [Features 1, 2, 3] Rolling averages over last 30 games (keep columns via transform)\n",
    "# Note: if only July games exist and there are fewer than 30, set min_periods to allow NaN.\n",
    "base_df = base_df.sort_values(['team', 'year', 'month', 'day', 'game_id'])\n",
    "\n",
    "# Average runs scored and allowed\n",
    "base_df['f1_avg_runs_scored_30'] = base_df.groupby('team')['r'].transform(lambda x: x.shift(1).rolling(window=30, min_periods=1).mean())\n",
    "base_df['f2_avg_runs_allowed_30'] = base_df.groupby('team')['runs_allowed'].transform(lambda x: x.shift(1).rolling(window=30, min_periods=1).mean())\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 7-1] Rolling average over last 30 games (runs scored/allowed)\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: team-sorted r and runs_allowed\")\n",
    "print(f\"Expected Output: mean runs scored/allowed over last 30 games (NaN allowed)\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - f1_avg_runs_scored_30: NaN={base_df['f1_avg_runs_scored_30'].isna().sum()}, min={base_df['f1_avg_runs_scored_30'].min():.2f}, max={base_df['f1_avg_runs_scored_30'].max():.2f}\")\n",
    "print(f\"  - f2_avg_runs_allowed_30: NaN={base_df['f2_avg_runs_allowed_30'].isna().sum()}, min={base_df['f2_avg_runs_allowed_30'].min():.2f}, max={base_df['f2_avg_runs_allowed_30'].max():.2f}\")\n",
    "print(f\"  - sample:\\n{base_df[['team', 'f1_avg_runs_scored_30', 'f2_avg_runs_allowed_30']].head(10)}\")\n",
    "print()\n",
    "\n",
    "# Team batting average (cumulative sums are more accurate)\n",
    "rolling_hits = base_df.groupby('team')['hit'].transform(lambda x: x.shift(1).rolling(window=30, min_periods=1).sum())\n",
    "rolling_ab = base_df.groupby('team')['bat_num'].transform(lambda x: x.shift(1).rolling(window=30, min_periods=1).sum())\n",
    "base_df['f3_team_batting_avg_30'] = rolling_hits / rolling_ab\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 7-2] Team batting average over last 30 games\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: 30-game rolling sums of team hit and bat_num\")\n",
    "print(f\"Expected Output: team batting average = rolling_hits / rolling_ab\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - f3_team_batting_avg_30: NaN={base_df['f3_team_batting_avg_30'].isna().sum()}, min={base_df['f3_team_batting_avg_30'].min():.4f}, max={base_df['f3_team_batting_avg_30'].max():.4f}\")\n",
    "print(f\"  - sample:\\n{base_df[['team', 'hit', 'bat_num', 'f3_team_batting_avg_30']].head(10)}\")\n",
    "print()\n",
    "\n",
    "# 5. [Feature 4] Starting pitcher season average runs allowed\n",
    "starters = pt[pt['mound'] == 1][['idx', 'name', 'losescore']].copy()\n",
    "starters = pd.merge(starters, sb[['idx', 'year', 'month', 'day']], on='idx')\n",
    "starters = starters.sort_values(['name', 'year', 'month', 'day'])\n",
    "starters['f4_pitcher_runs_avg'] = starters.groupby('name')['losescore'].transform(lambda x: x.shift(1).expanding().mean())\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 8] Starting pitcher season average runs allowed\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: pitcher data (filtered to mound==1)\")\n",
    "print(f\"Expected Output: cumulative mean runs allowed per pitcher (expanding mean)\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - starters shape: {starters.shape}\")\n",
    "print(f\"  - f4_pitcher_runs_avg: NaN={starters['f4_pitcher_runs_avg'].isna().sum()}, min={starters['f4_pitcher_runs_avg'].min():.2f}, max={starters['f4_pitcher_runs_avg'].max():.2f}\")\n",
    "print(f\"  - sample:\\n{starters[['name', 'losescore', 'f4_pitcher_runs_avg']].head(10)}\")\n",
    "print()\n",
    "\n",
    "base_df = pd.merge(base_df, starters[['idx', 'f4_pitcher_runs_avg']], on='idx', how='left')\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 8-2] Add pitcher info to base_df\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: base_df + starters f4_pitcher_runs_avg\")\n",
    "print(f\"Expected Output: merge on idx\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - base_df shape: {base_df.shape}\")\n",
    "print(f\"  - f4_pitcher_runs_avg: NaN={base_df['f4_pitcher_runs_avg'].isna().sum()}\")\n",
    "print()\n",
    "\n",
    "# 6. [Feature 5] Team overall win rate\n",
    "base_df['f5_total_win_pct'] = base_df.groupby('team')['win_binary'].transform(lambda x: x.shift(1).expanding().mean())\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 9] Team overall win rate\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: team win_binary\")\n",
    "print(f\"Expected Output: cumulative win rate (expanding mean)\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - f5_total_win_pct: NaN={base_df['f5_total_win_pct'].isna().sum()}, min={base_df['f5_total_win_pct'].min():.4f}, max={base_df['f5_total_win_pct'].max():.4f}\")\n",
    "print(f\"  - sample:\\n{base_df[['team', 'win_binary', 'f5_total_win_pct']].head(10)}\")\n",
    "print()\n",
    "\n",
    "# 7. [Feature 6] Home/away win rate\n",
    "def calc_ha_win_pct(df):\n",
    "    df = df.copy()\n",
    "    df['is_home'] = (df['team'] == df['home'])\n",
    "    # Compute win rate separately for home vs away for each team\n",
    "    df['f6_ha_win_pct'] = df.groupby(['team', 'is_home'])['win_binary'].transform(lambda x: x.shift(1).expanding().mean())\n",
    "    return df\n",
    "\n",
    "base_df = calc_ha_win_pct(base_df)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 10] Home/away win rate\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: team and is_home (home/away flag)\")\n",
    "print(f\"Expected Output: cumulative win rate by team-is_home\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - f6_ha_win_pct: NaN={base_df['f6_ha_win_pct'].isna().sum()}, min={base_df['f6_ha_win_pct'].min():.4f}, max={base_df['f6_ha_win_pct'].max():.4f}\")\n",
    "print(f\"  - is_home distribution: {base_df['is_home'].value_counts().to_dict()}\")\n",
    "print(f\"  - sample:\\n{base_df[['team', 'is_home', 'win_binary', 'f6_ha_win_pct']].head(10)}\")\n",
    "print()\n",
    "\n",
    "# 8. Build final MLP dataset\n",
    "feature_cols = ['f1_avg_runs_scored_30', 'f2_avg_runs_allowed_30', 'f3_team_batting_avg_30', \n",
    "                'f4_pitcher_runs_avg', 'f5_total_win_pct', 'f6_ha_win_pct']\n",
    "\n",
    "# Split home-team and away-team data then join\n",
    "home_df = base_df[base_df['team'] == base_df['home']][['game_id', 'win_binary'] + feature_cols]\n",
    "home_df.columns = ['game_id', 'home_win'] + ['h_' + c for c in feature_cols]\n",
    "\n",
    "away_df = base_df[base_df['team'] == base_df['away']][['game_id'] + feature_cols]\n",
    "away_df.columns = ['game_id'] + ['a_' + c for c in feature_cols]\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 11-1] Split home/away data\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: all game records in base_df\")\n",
    "print(f\"Expected Output: separate rows for home and away teams\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - home_df shape: {home_df.shape}\")\n",
    "print(f\"  - away_df shape: {away_df.shape}\")\n",
    "print(f\"  - home_df sample:\\n{home_df.head()}\")\n",
    "print(f\"  - away_df sample:\\n{away_df.head()}\")\n",
    "print()\n",
    "\n",
    "final_dataset = pd.merge(home_df, away_df, on='game_id').dropna()\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 11-2] Merge home/away data and drop NaN\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: home_df, away_df (on game_id)\")\n",
    "print(f\"Expected Output: rows with both home/away features per game_id\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - rows before merge: {len(home_df)}\")\n",
    "print(f\"  - rows after merge (before dropna): {len(pd.merge(home_df, away_df, on='game_id'))}\")\n",
    "print(f\"  - final_dataset shape (after dropna): {final_dataset.shape}\")\n",
    "print(f\"  - columns: {list(final_dataset.columns)}\")\n",
    "print()\n",
    "\n",
    "# Target: 0 if home team wins, 1 if away team wins\n",
    "final_dataset['target'] = (final_dataset['home_win'] == 0).astype(int)\n",
    "final_dataset = final_dataset.drop(columns=['home_win'])\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 12] Create target label\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: home_win (home win=1, away win=0)\")\n",
    "print(f\"Expected Output: target (home win=0, away win=1)\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - target distribution: {final_dataset['target'].value_counts().to_dict()}\")\n",
    "print(f\"  - target ratio: home wins (0)={final_dataset[final_dataset['target']==0].shape[0]/len(final_dataset):.2%}, away wins (1)={final_dataset[final_dataset['target']==1].shape[0]/len(final_dataset):.2%}\")\n",
    "print(f\"  - sample:\\n{final_dataset[['game_id', 'target']].head()}\")\n",
    "print()\n",
    "\n",
    "# Save\n",
    "final_dataset.to_csv('kbo_mlp_training_data.csv', index=False)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"[STEP 13] Save final dataset\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Input: final_dataset\")\n",
    "print(f\"Expected Output: kbo_mlp_training_data.csv saved\")\n",
    "print(f\"Real Output:\")\n",
    "print(f\"  - filename: kbo_mlp_training_data.csv\")\n",
    "print(f\"  - final shape: {final_dataset.shape}\")\n",
    "print(f\"  - column count: {len(final_dataset.columns)}\")\n",
    "print(f\"  - columns: {list(final_dataset.columns)}\")\n",
    "print(f\"\\nTraining dataset built: {len(final_dataset)} games included\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7728fe",
   "metadata": {},
   "source": [
    "### scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b6464e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load preprocessed data\n",
    "df = pd.read_csv('kbo_mlp_training_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5fba7e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Split features (X) and labels (y)\n",
    "# game_id is an identifier and excluded; predict target (0: home win, 1: away win)\n",
    "X = df.drop(columns=['game_id', 'target'])\n",
    "y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0776f210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Split data (75% train, 25% test)\n",
    "# shuffle=False keeps chronological order for testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, shuffle=False)\n",
    "\n",
    "# 4. Scale data with StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec7bf9f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: SGD | Accuracy: 52.2%\n",
      "Algorithm: ADAM | Accuracy: 56.2%\n",
      "Algorithm: LBFGS | Accuracy: 49.3%\n"
     ]
    }
   ],
   "source": [
    "# 5. Compare three optimization algorithms (solvers)\n",
    "solvers = ['sgd', 'adam', 'lbfgs']\n",
    "results = {}\n",
    "\n",
    "for s in solvers:\n",
    "    # Use config from reference: hidden layer (3,), activation relu, max_iter 1000\n",
    "    clf = MLPClassifier(\n",
    "    hidden_layer_sizes=(3,),\n",
    "    activation='relu',\n",
    "    solver=s,\n",
    "    max_iter=1000, \n",
    "    random_state=42\n",
    "    )\n",
    "    \n",
    "    # Train model\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict and compute accuracy\n",
    "    y_pred = clf.predict(X_test_scaled)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    results[s] = acc\n",
    "    print(f\"Algorithm: {s.upper()} | Accuracy: {acc:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fcf22671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Recommended algorithm: ADAM (accuracy 56.2%)\n"
     ]
    }
   ],
   "source": [
    "# Identify algorithm with highest accuracy\n",
    "best_solver = max(results, key=results.get)\n",
    "print(f\"\\nRecommended algorithm: {best_solver.upper()} (accuracy {results[best_solver]:.1%})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b5f6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ea40e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:606: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:606: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:606: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:606: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:606: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:606: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:606: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:606: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:606: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:785: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (1000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.11/site-packages/sklearn/neural_network/_multilayer_perceptron.py:606: ConvergenceWarning: lbfgs failed to converge after 5000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=5000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV accuracy: 54.9%\n",
      "Best params: {'activation': 'tanh', 'hidden_layer_sizes': (6,), 'max_iter': 1000, 'solver': 'lbfgs'}\n",
      "Final test accuracy: 51.1%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 1. Scale data (critical for neural nets)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 2. Define parameter grid to test\n",
    "param_grid = {\n",
    "    'hidden_layer_sizes': [(3,), (6,), (12,), (6, 3), (12, 6)], # try wider or deeper\n",
    "    'solver': ['sgd', 'adam', 'lbfgs'],\n",
    "    'activation': ['relu', 'tanh'],\n",
    "    'max_iter': [1000, 5000] # allow sufficient iterations\n",
    "}\n",
    "\n",
    "# 3. Run grid search (test all combinations to find the best)\n",
    "mlp = MLPClassifier(random_state=1)\n",
    "grid_search = GridSearchCV(mlp, param_grid, cv=3, scoring='accuracy', n_jobs=-1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 4. Report results\n",
    "print(f\"Best CV accuracy: {grid_search.best_score_:.1%}\")\n",
    "print(f\"Best params: {grid_search.best_params_}\")\n",
    "\n",
    "# 5. Evaluate best model on test data\n",
    "best_model = grid_search.best_estimator_\n",
    "test_acc = best_model.score(X_test_scaled, y_test)\n",
    "print(f\"Final test accuracy: {test_acc:.1%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15eccb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/200] Loss: 0.6814 | Train Acc: 51.7% | Test Acc: 54.8%\n",
      "Epoch [40/200] Loss: 0.6784 | Train Acc: 53.5% | Test Acc: 48.8%\n",
      "Epoch [60/200] Loss: 0.6905 | Train Acc: 53.7% | Test Acc: 50.7%\n",
      "Epoch [80/200] Loss: 0.6946 | Train Acc: 53.7% | Test Acc: 51.2%\n",
      "Epoch [100/200] Loss: 0.6976 | Train Acc: 54.6% | Test Acc: 53.5%\n",
      "Epoch [120/200] Loss: 0.6813 | Train Acc: 54.0% | Test Acc: 53.9%\n",
      "Epoch [140/200] Loss: 0.6842 | Train Acc: 54.5% | Test Acc: 56.7%\n",
      "Epoch [160/200] Loss: 0.7154 | Train Acc: 55.4% | Test Acc: 55.8%\n",
      "Epoch [180/200] Loss: 0.6792 | Train Acc: 54.5% | Test Acc: 54.4%\n",
      "Epoch [200/200] Loss: 0.6980 | Train Acc: 54.8% | Test Acc: 55.3%\n",
      "\n",
      "[Final test accuracy]: 55.30%\n"
     ]
    }
   ],
   "source": [
    "# 1. Load and preprocess data\n",
    "df = pd.read_csv('kbo_mlp_training_data.csv')\n",
    "X = df.drop(columns=['game_id', 'target']).values\n",
    "y = df['target'].values.reshape(-1, 1)\n",
    "\n",
    "# Split data (keep chronological order)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert to tensors\n",
    "X_train_t = torch.FloatTensor(X_train_scaled)\n",
    "y_train_t = torch.FloatTensor(y_train)\n",
    "X_test_t = torch.FloatTensor(X_test_scaled)\n",
    "y_test_t = torch.FloatTensor(y_test)\n",
    "\n",
    "train_loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=72, shuffle=True)\n",
    "\n",
    "# 2. Model design (add Dropout for regularization)\n",
    "class AdvancedKBOPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AdvancedKBOPredictor, self).__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(12, 8),\n",
    "            nn.Tanh(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(8, 4),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(4, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.layers(x)\n",
    "\n",
    "# Model, loss, optimizer\n",
    "model = AdvancedKBOPredictor()\n",
    "criterion = nn.BCELoss()\n",
    "# weight_decay adds L2 regularization to keep weights controlled\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-2)\n",
    "\n",
    "# 3. Training loop\n",
    "epochs = 200\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    # Print evaluation every 20 epochs\n",
    "    if (epoch + 1) % 20 == 0:\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            train_outputs = model(X_train_t)\n",
    "            train_acc = ((train_outputs > 0.5).float() == y_train_t).float().mean()\n",
    "            \n",
    "            test_outputs = model(X_test_t)\n",
    "            test_acc = ((test_outputs > 0.5).float() == y_test_t).float().mean()\n",
    "            \n",
    "            print(f\"Epoch [{epoch+1}/{epochs}] Loss: {loss.item():.4f} | Train Acc: {train_acc:.1%} | Test Acc: {test_acc:.1%}\")\n",
    "\n",
    "# 4. Final evaluation\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    final_pred = (model(X_test_t) > 0.5).float()\n",
    "    print(f\"\\n[Final test accuracy]: {accuracy_score(y_test, final_pred):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46390935",
   "metadata": {},
   "source": [
    "### Result: \n",
    "Loss\n",
    "- How wrong the model is(lower is better)\n",
    "\n",
    "Train Accuracy\n",
    "- Practice test score\n",
    "- 54: the model has only barely learned a pattern\n",
    "\n",
    "Test Accuracy\n",
    "- Real exam score\n",
    "- 55\n",
    "Current model status : Not overfitting, Not a lack of training epochs, The information, features, is weak, or the model is too simple\n",
    "\n",
    "232425 notebook has more data, but performance with 24June - 2025 data is better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb107b51",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
